{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Welcome to Modal notebooks!\n",
        "\n",
        "Write Python code and collaborate in real time. Your code runs in Modal's\n",
        "**serverless cloud**, and anyone in the same workspace can join.\n",
        "\n",
        "This notebook comes with some common Python libraries installed. Run\n",
        "cells with `Shift+Enter`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "# ===================== FitMate \u2013 Full Fitness Coach Agent (Fast Version) =====================\n",
        "\n",
        "# ===== 0) Install Dependencies =====\n",
        "%uv pip install -q gradio transformers accelerate bitsandbytes\n",
        "%uv pip install -q sentence-transformers faiss-cpu pypdf2\n",
        "%uv pip install -q duckduckgo-search beautifulsoup4 requests\n",
        "%uv pip install -q huggingface_hub torch\n",
        "%uv pip install -q --upgrade typing_extensions regex\n",
        "\n",
        "# ===== 1) Imports =====\n",
        "import os\n",
        "import re\n",
        "import warnings\n",
        "from typing import Type, List, Dict\n",
        "\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import PyPDF2\n",
        "import faiss\n",
        "import requests\n",
        "import torch\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from duckduckgo_search import DDGS\n",
        "from huggingface_hub import login\n",
        "from pydantic import BaseModel, Field\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        ")\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ===================== 2) Load FitMate model (4-bit if possible) =====================\n",
        "\n",
        "print(\"\u23f3 Loading FitMate model on GPU if available...\")\n",
        "\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
        "if not HF_TOKEN:\n",
        "    raise ValueError(\"HF_TOKEN environment variable is not set. Please set it in your environment variables.\")\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"moamenshamed/fitmate\", token=HF_TOKEN)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = None\n",
        "try:\n",
        "    # \u0645\u062d\u0627\u0648\u0644\u0629 \u062a\u062d\u0645\u064a\u0644 4-bit \u0639\u0634\u0627\u0646 \u0627\u0644\u0633\u0631\u0639\u0629\n",
        "    print(\"Trying to load model in 4-bit quantization...\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"moamenshamed/fitmate\",\n",
        "        token=HF_TOKEN,\n",
        "        device_map=\"auto\",\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "    )\n",
        "    print(\"\u2705 Loaded in 4-bit mode.\")\n",
        "except Exception as e:\n",
        "    print(\"\u26a0\ufe0f 4-bit load failed, falling back to standard fp16/fp32. Reason:\", e)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"moamenshamed/fitmate\",\n",
        "        token=HF_TOKEN,\n",
        "        device_map=\"auto\" if device == \"cuda\" else None,\n",
        "        torch_dtype=torch.bfloat16 if device == \"cuda\" else torch.float32,\n",
        "        low_cpu_mem_usage=True,\n",
        "    )\n",
        "\n",
        "model.eval()\n",
        "\n",
        "print(f\"\u2705 FitMate loaded on: {device}\")\n",
        "if device == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "print()\n",
        "\n",
        "# ===================== 3) System Instructions =====================\n",
        "\n",
        "offtopic_rule = (\n",
        "    \"If the user asks about anything outside fitness, workouts, nutrition, health, \"\n",
        "    \"or healthy lifestyle, politely decline in ONE short sentence and vary the wording \"\n",
        "    \"each time (do not repeat the same sentence). After declining, briefly invite a \"\n",
        "    \"fitness-related question. Do not mention policies or rules.\"\n",
        ")\n",
        "\n",
        "BASE_SYSTEM_PROMPT = (\n",
        "    \"You are FitMate, a highly knowledgeable AI assistant specializing ONLY in fitness, \"\n",
        "    \"workouts, nutrition, health, recovery and lifestyle improvement.\\n\\n\"\n",
        "    \"CORE RULES:\\n\"\n",
        "    \"\u2022 Stay strictly within fitness, health, nutrition, mindset, sleep and healthy lifestyle.\\n\"\n",
        "    \"\u2022 If the user asks about anything outside these topics, politely decline by saying you can \"\n",
        "    \"only discuss fitness and healthy living. \" + offtopic_rule + \"\\n\"\n",
        "    \"\u2022 Never mention that you are following rules or policies.\\n\\n\"\n",
        "    \"COACHING STYLE:\\n\"\n",
        "    \"\u2022 Think like an experienced personal trainer + nutrition coach.\\n\"\n",
        "    \"\u2022 Be detailed, motivating and practical (no fluff, always actionable).\\n\"\n",
        "    \"\u2022 For goals like weight loss, muscle gain or full programs, structure your \"\n",
        "    \"response into clear sections (Assessment, Nutrition Plan, Workout Plan, Recovery, Tracking).\\n\"\n",
        "    \"\u2022 Ask for missing information you need (weight, height, age, activity level, equipment, injuries).\\n\"\n",
        "    \"\u2022 Adapt your advice to the user's goal: fat loss, muscle gain, strength, general health, performance, etc.\\n\"\n",
        "    \"\u2022 Give complete answers, not overly short summaries.\\n\"\n",
        "    \"\u2022 Always finish your answer with a short, friendly follow-up question inviting the user to continue.\\n\"\n",
        "    \"\u2022 Never cut off mid-sentence; complete your thought before stopping.\\n\\n\"\n",
        "    \"LANGUAGE:\\n\"\n",
        "    \"\u2022 Detect the user's language automatically.\\n\"\n",
        "    \"\u2022 If they write mainly in Arabic, answer fully in Arabic (Egyptian dialect is fine) unless a term is better in English.\\n\"\n",
        "    \"\u2022 If they write mainly in English, answer in English.\\n\"\n",
        "    \"\u2022 If they mix Arabic and English, you may mix the languages naturally.\\n\"\n",
        ")\n",
        "\n",
        "# ===================== 4) Tools (Web Search + Scrape) =====================\n",
        "\n",
        "class WebSearchToolInput(BaseModel):\n",
        "    query: str = Field(..., description=\"Search query\")\n",
        "\n",
        "class WebSearchTool:\n",
        "    name: str = \"web_search\"\n",
        "    description: str = \"Search the web using DuckDuckGo for current health and fitness information\"\n",
        "    args_schema: Type[BaseModel] = WebSearchToolInput\n",
        "    \n",
        "    def run(self, query: str) -> str:\n",
        "        try:\n",
        "            ddgs = DDGS()\n",
        "            results = ddgs.text(query, max_results=5)\n",
        "            if not results:\n",
        "                return \"No web results found.\"\n",
        "            summary = f\"Web search results for: {query}\\n\\n\"\n",
        "            for i, r in enumerate(results, 1):\n",
        "                summary += f\"{i}. {r['title']}\\n   {r['body']}\\n   {r['href']}\\n\\n\"\n",
        "            return summary[:3000]\n",
        "        except Exception as e:\n",
        "            return f\"Search error: {str(e)}\"\n",
        "\n",
        "class ScrapeWebsiteToolInput(BaseModel):\n",
        "    url: str = Field(..., description=\"URL to scrape\")\n",
        "\n",
        "class ScrapeWebsiteTool:\n",
        "    name: str = \"scrape_website\"\n",
        "    description: str = \"Scrape content from a website URL\"\n",
        "    args_schema: Type[BaseModel] = ScrapeWebsiteToolInput\n",
        "    \n",
        "    def run(self, url: str) -> str:\n",
        "        try:\n",
        "            headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "            response = requests.get(url, headers=headers, timeout=10)\n",
        "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "            paragraphs = soup.find_all(\"p\")\n",
        "            content = \"\\n\".join([p.get_text() for p in paragraphs[:10]])\n",
        "            if not content.strip():\n",
        "                return \"No readable text content found on this page.\"\n",
        "            return f\"Website Content (first paragraphs):\\n\\n{content[:3000]}\"\n",
        "        except Exception as e:\n",
        "            return f\"Scraping error: {str(e)}\"\n",
        "\n",
        "web_search_tool = WebSearchTool()\n",
        "scrape_website_tool = ScrapeWebsiteTool()\n",
        "\n",
        "# ===================== 5) RAG: FAISS Vector Store =====================\n",
        "\n",
        "class FAISSVectorStore:\n",
        "    def __init__(self):\n",
        "        self.embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "        self.dimension = 384\n",
        "        self.index = faiss.IndexFlatL2(self.dimension)\n",
        "        self.chunks: List[str] = []\n",
        "        self.metadata: List[dict] = []\n",
        "    \n",
        "    def add_pdf(self, pdf_path: str):\n",
        "        try:\n",
        "            pdf_reader = PyPDF2.PdfReader(pdf_path)\n",
        "            chunks_data = []\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                text = page.extract_text()\n",
        "                if text and text.strip():\n",
        "                    chunk_size = 500\n",
        "                    for i in range(0, len(text), chunk_size):\n",
        "                        chunk_text = text[i : i + chunk_size].strip()\n",
        "                        if len(chunk_text) > 100:\n",
        "                            chunks_data.append({\"text\": chunk_text, \"page\": page_num + 1})\n",
        "            \n",
        "            if not chunks_data:\n",
        "                return \"\u274c No text extracted from PDF\"\n",
        "            \n",
        "            texts = [c[\"text\"] for c in chunks_data]\n",
        "            embeddings = self.embedding_model.encode(texts, show_progress_bar=False)\n",
        "            embeddings = np.array(embeddings).astype(\"float32\")\n",
        "            \n",
        "            self.index.add(embeddings)\n",
        "            self.chunks.extend(texts)\n",
        "            self.metadata.extend([{\"page\": c[\"page\"]} for c in chunks_data])\n",
        "            \n",
        "            return f\"\u2705 Loaded {len(chunks_data)} chunks from {len(pdf_reader.pages)} pages\"\n",
        "        except Exception as e:\n",
        "            return f\"\u274c Error processing PDF: {str(e)}\"\n",
        "    \n",
        "    def get_context(self, query: str, top_k: int = 3) -> str:\n",
        "        if len(self.chunks) == 0:\n",
        "            return \"\"\n",
        "        \n",
        "        query_emb = self.embedding_model.encode([query])\n",
        "        query_emb = np.array(query_emb).astype(\"float32\")\n",
        "        distances, indices = self.index.search(query_emb, min(top_k, len(self.chunks)))\n",
        "        \n",
        "        results = []\n",
        "        for idx, dist in zip(indices[0], distances[0]):\n",
        "            if idx < len(self.chunks) and dist < 1.5:\n",
        "                results.append(f\"[Page {self.metadata[idx]['page']}] {self.chunks[idx]}\")\n",
        "        \n",
        "        return \"\\n\\n\".join(results) if results else \"\"\n",
        "    \n",
        "    def clear(self):\n",
        "        self.index = faiss.IndexFlatL2(self.dimension)\n",
        "        self.chunks = []\n",
        "        self.metadata = []\n",
        "\n",
        "print(\"Initializing vector store...\")\n",
        "vector_store = FAISSVectorStore()\n",
        "print(\"\u2705 Vector store ready!\\n\")\n",
        "\n",
        "# ===================== 6) Generation \u2013 Faster Settings =====================\n",
        "\n",
        "def clean_fitmate_output(text: str) -> str:\n",
        "    original = text\n",
        "    lower = text.lower()\n",
        "\n",
        "    idx = lower.rfind(\"final\")\n",
        "    if idx != -1 and idx + len(\"final\") < len(text):\n",
        "        text = text[idx + len(\"final\"):]\n",
        "\n",
        "    text = text.lstrip(\" \\n:-\")\n",
        "    if text.lower().startswith(\"analysis\"):\n",
        "        dot_idx = text.find(\".\")\n",
        "        if dot_idx != -1 and dot_idx + 1 < len(text):\n",
        "            text = text[dot_idx + 1:]\n",
        "\n",
        "    text = re.sub(r\"^user says[:\\s\\\"\u201c]+\", \"\", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\"^the user says[:\\s\\\"\u201c]+\", \"\", text, flags=re.IGNORECASE)\n",
        "\n",
        "    text = text.strip()\n",
        "    return text if text else original.strip()\n",
        "\n",
        "def generate_with_fitmate_chat(\n",
        "    user_content: str,\n",
        "    max_new_tokens_cap: int = 1024,   # \u0627\u0641\u062a\u0631\u0627\u0636\u064a \u0623\u0633\u0631\u0639\n",
        "    temperature: float = 0.4,        # \u0623\u0642\u0644 \u0639\u0634\u0648\u0627\u0626\u064a\u0629 \u2192 \u0623\u0633\u0631\u0639\n",
        ") -> str:\n",
        "    # \u0646\u0642\u0644\u0644 \u0637\u0648\u0644 \u0627\u0644\u0640 system prompt \u0639\u0634\u0627\u0646 \u0627\u0644\u0633\u0631\u0639\u0629\n",
        "    system_short = BASE_SYSTEM_PROMPT[:1500]\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_short},\n",
        "        {\"role\": \"user\", \"content\": user_content},\n",
        "    ]\n",
        "\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\",\n",
        "        return_dict=True,\n",
        "    ).to(model.device)\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "\n",
        "    eos_id = getattr(tokenizer, \"eos_token_id\", None)\n",
        "    pad_id = getattr(tokenizer, \"pad_token_id\", None)\n",
        "    if pad_id is None:\n",
        "        pad_id = eos_id\n",
        "\n",
        "    context_window = int(getattr(model.config, \"max_position_embeddings\", 4096))\n",
        "    input_length = int(input_ids.shape[1])\n",
        "    available = context_window - input_length - 32\n",
        "    if available <= 0:\n",
        "        raise ValueError(\n",
        "            f\"No room left to generate tokens (input={input_length}, window={context_window}). \"\n",
        "            \"Try shortening the conversation or question.\"\n",
        "        )\n",
        "\n",
        "    max_new_tokens = min(max_new_tokens_cap, available)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=0.9,\n",
        "            do_sample=True,\n",
        "            no_repeat_ngram_size=3,\n",
        "            use_cache=True,        # \u0645\u0647\u0645 \u0644\u0644\u0633\u0631\u0639\u0629\n",
        "            eos_token_id=eos_id,\n",
        "            pad_token_id=pad_id,\n",
        "        )\n",
        "\n",
        "    generated_ids = outputs[0][input_length:]\n",
        "    answer_text = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
        "    answer_text = clean_fitmate_output(answer_text)\n",
        "    return answer_text\n",
        "\n",
        "# ===================== 7) Agent Logic + Language Detection + LoRA-mode =====================\n",
        "\n",
        "def detect_language(text: str) -> str:\n",
        "    arabic_chars = len(re.findall(r\"[\\u0600-\\u06FF]\", text))\n",
        "    latin_chars = len(re.findall(r\"[A-Za-z]\", text))\n",
        "    if arabic_chars > latin_chars and arabic_chars > 0:\n",
        "        return \"arabic\"\n",
        "    if latin_chars > arabic_chars and latin_chars > 0:\n",
        "        return \"english\"\n",
        "    return \"mixed\"\n",
        "\n",
        "def build_agent_user_message(\n",
        "    question: str,\n",
        "    doc_context: str,\n",
        "    web_info: str,\n",
        "    lora_mode: str,\n",
        ") -> str:\n",
        "    parts = []\n",
        "\n",
        "    lang = detect_language(question)\n",
        "    if lang == \"arabic\":\n",
        "        parts.append(\n",
        "            \"The user is writing mainly in Arabic. Answer ONLY in Arabic (Egyptian dialect is fine), \"\n",
        "            \"unless a specific term is clearly better in English.\\n\\n\"\n",
        "        )\n",
        "    elif lang == \"english\":\n",
        "        parts.append(\n",
        "            \"The user is writing mainly in English. Answer in English.\\n\\n\"\n",
        "        )\n",
        "    else:\n",
        "        parts.append(\n",
        "            \"The user is mixing Arabic and English. You may mix both languages naturally.\\n\\n\"\n",
        "        )\n",
        "\n",
        "    if lora_mode and \"Fat-loss\" in lora_mode:\n",
        "        parts.append(\"Coaching mode: focus on safe but effective fat-loss, calorie deficit, and adherence.\\n\\n\")\n",
        "    elif lora_mode and \"Muscle\" in lora_mode:\n",
        "        parts.append(\"Coaching mode: focus on hypertrophy, strength, progressive overload, and high-protein nutrition.\\n\\n\")\n",
        "    elif lora_mode and \"Rehab\" in lora_mode:\n",
        "        parts.append(\"Coaching mode: focus on gentle exercises, mobility, pain-free range of motion, and recovery.\\n\\n\")\n",
        "\n",
        "    if doc_context:\n",
        "        parts.append(\n",
        "            \"Below is some DOCUMENT context from the user's fitness/nutrition PDFs. \"\n",
        "            \"Use it only if it clearly helps answer the question:\\n\\n\"\n",
        "            f\"{doc_context}\\n\\n\"\n",
        "        )\n",
        "\n",
        "    if web_info:\n",
        "        parts.append(\n",
        "            \"Below is some WEB SEARCH information about fitness/health that may be useful. \"\n",
        "            \"Use it as supportive evidence only, and DO NOT mention that it came from the web:\\n\\n\"\n",
        "            f\"{web_info}\\n\\n\"\n",
        "        )\n",
        "\n",
        "    parts.append(\n",
        "        \"Now answer the user's question directly, speaking to them as their fitness coach. \"\n",
        "        \"Do not talk about 'analysis' or 'steps', just give the advice itself.\\n\\n\"\n",
        "        f\"User question: {question}\\n\\n\"\n",
        "        \"Answer now in a clear, well-structured, motivational way.\"\n",
        "    )\n",
        "\n",
        "    return \"\".join(parts)\n",
        "\n",
        "def run_agent(\n",
        "    question: str,\n",
        "    enable_web: bool,\n",
        "    max_tokens: int,\n",
        "    lora_mode: str,\n",
        ") -> str:\n",
        "    try:\n",
        "        doc_context = vector_store.get_context(question)\n",
        "\n",
        "        lower_q = question.lower()\n",
        "        need_web = (\n",
        "            enable_web\n",
        "            and any(\n",
        "                kw in lower_q\n",
        "                for kw in [\n",
        "                    \"latest\",\n",
        "                    \"recent\",\n",
        "                    \"new study\",\n",
        "                    \"new research\",\n",
        "                    \"2023\",\n",
        "                    \"2024\",\n",
        "                    \"\u0623\u062d\u062f\u062b\",\n",
        "                    \"\u0622\u062e\u0631 \u0623\u0628\u062d\u0627\u062b\",\n",
        "                    \"\u062f\u0631\u0627\u0633\u0629 \u062c\u062f\u064a\u062f\u0629\",\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        web_info = \"\"\n",
        "        if need_web:\n",
        "            web_info = web_search_tool.run(question)\n",
        "\n",
        "        user_msg = build_agent_user_message(question, doc_context, web_info, lora_mode)\n",
        "        answer = generate_with_fitmate_chat(user_msg, max_new_tokens_cap=max_tokens, temperature=0.4)\n",
        "        return answer\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"\u274c Error inside agent: {str(e)}\"\n",
        "\n",
        "# ===================== 8) Multi-Chat & Helpers (messages format) =====================\n",
        "\n",
        "# chat_histories: Dict[str, List[{\"role\":..., \"content\":...}]]\n",
        "\n",
        "def create_new_chat(chat_histories: Dict[str, List[Dict[str, str]]]):\n",
        "    idx = len(chat_histories) + 1\n",
        "    chat_id = f\"Chat {idx}\"\n",
        "    chat_histories[chat_id] = []\n",
        "    choices = list(chat_histories.keys())\n",
        "    return chat_histories, chat_id, gr.update(choices=choices, value=chat_id), []\n",
        "\n",
        "def switch_chat(selected_chat: str, chat_histories: Dict[str, List[Dict[str, str]]]):\n",
        "    history = chat_histories.get(selected_chat, [])\n",
        "    return history\n",
        "\n",
        "def delete_chat(chat_histories, current_chat):\n",
        "    if current_chat in chat_histories:\n",
        "        chat_histories.pop(current_chat)\n",
        "    if not chat_histories:\n",
        "        chat_histories[\"Chat 1\"] = []\n",
        "        current_chat = \"Chat 1\"\n",
        "    else:\n",
        "        current_chat = list(chat_histories.keys())[0]\n",
        "    choices = list(chat_histories.keys())\n",
        "    return chat_histories, current_chat, gr.update(choices=choices, value=current_chat), chat_histories[current_chat]\n",
        "\n",
        "def upload_pdf(pdf_file):\n",
        "    if pdf_file is None:\n",
        "        return \"\u26a0\ufe0f No file uploaded\"\n",
        "    return vector_store.add_pdf(pdf_file)\n",
        "\n",
        "def add_user_message(message, chat_histories, current_chat):\n",
        "    if not message or not message.strip():\n",
        "        return chat_histories, chat_histories.get(current_chat, [])\n",
        "    history = chat_histories.get(current_chat, [])\n",
        "    history.append({\"role\": \"user\", \"content\": message})\n",
        "    chat_histories[current_chat] = history\n",
        "    return chat_histories, history\n",
        "\n",
        "def generate_bot_reply(enable_web, max_tokens, lora_mode, chat_histories, current_chat):\n",
        "    history = chat_histories.get(current_chat, [])\n",
        "    if not history:\n",
        "        return chat_histories, history\n",
        "    if history[-1][\"role\"] != \"user\":\n",
        "        return chat_histories, history\n",
        "\n",
        "    user_message = history[-1][\"content\"]\n",
        "    bot_response = run_agent(user_message, enable_web, int(max_tokens), lora_mode)\n",
        "    history.append({\"role\": \"assistant\", \"content\": bot_response})\n",
        "    chat_histories[current_chat] = history\n",
        "    return chat_histories, history\n",
        "\n",
        "def clear_current_chat(chat_histories, current_chat):\n",
        "    chat_histories[current_chat] = []\n",
        "    return chat_histories, []\n",
        "\n",
        "def clear_documents():\n",
        "    vector_store.clear()\n",
        "    return \"\u2705 All documents cleared from memory\"\n",
        "\n",
        "def update_account_name(new_name: str):\n",
        "    new_name = (new_name or \"\").strip()\n",
        "    if not new_name:\n",
        "        new_name = \"Guest Account\"\n",
        "    return new_name, gr.update(value=f\"<div class='account-name'>\ud83d\udc64 {new_name}</div>\")\n",
        "\n",
        "def rename_chat(new_name: str, chat_histories, current_chat):\n",
        "    new_name = (new_name or \"\").strip()\n",
        "    if not new_name or new_name == current_chat:\n",
        "        return chat_histories, current_chat, gr.update(), gr.update(value=current_chat)\n",
        "    if new_name in chat_histories:\n",
        "        return chat_histories, current_chat, gr.update(), gr.update(value=current_chat)\n",
        "\n",
        "    chat_histories[new_name] = chat_histories.pop(current_chat)\n",
        "    current_chat = new_name\n",
        "    choices = list(chat_histories.keys())\n",
        "    return chat_histories, current_chat, gr.update(choices=choices, value=current_chat), gr.update(value=current_chat)\n",
        "\n",
        "def set_chat_name_box(chat_id: str):\n",
        "    return chat_id\n",
        "\n",
        "# ===================== 9) Gradio Interface \u2013 Clean Chat UI =====================\n",
        "\n",
        "with gr.Blocks(title=\"FitMate - AI Fitness Coach\") as demo:\n",
        "    gr.HTML(\"\"\"\n",
        "    <style>\n",
        "        /* Global Reset & Deep Purple Theme */\n",
        "        body, .gradio-container {\n",
        "            background: linear-gradient(135deg, #0f0518 0%, #1a0b2e 100%) !important;\n",
        "            color: #e9d5ff !important;\n",
        "            font-family: 'Inter', system-ui, -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, sans-serif !important;\n",
        "            margin: 0;\n",
        "            padding: 0;\n",
        "        }\n",
        "        \n",
        "        /* Sidebar Styling */\n",
        "        .sidebar-container {\n",
        "            background-color: #130725; /* Darker purple */\n",
        "            border-right: 1px solid #2d1b4e;\n",
        "            padding: 24px;\n",
        "            height: 100vh;\n",
        "            display: flex;\n",
        "            flex-direction: column;\n",
        "            box-shadow: 4px 0 24px rgba(0,0,0,0.4);\n",
        "        }\n",
        "        \n",
        "        .app-logo {\n",
        "            font-size: 1.8rem;\n",
        "            font-weight: 800;\n",
        "            background: linear-gradient(90deg, #a78bfa, #f472b6);\n",
        "            -webkit-background-clip: text;\n",
        "            -webkit-text-fill-color: transparent;\n",
        "            margin-bottom: 4px;\n",
        "            letter-spacing: -0.02em;\n",
        "        }\n",
        "        \n",
        "        .app-subtitle {\n",
        "            font-size: 0.85rem;\n",
        "            color: #9ca3af;\n",
        "            margin-bottom: 16px;\n",
        "            font-weight: 300;\n",
        "        }\n",
        "\n",
        "        .pro-badge {\n",
        "            background: linear-gradient(90deg, #7c3aed, #db2777);\n",
        "            color: white;\n",
        "            padding: 6px 12px;\n",
        "            border-radius: 8px;\n",
        "            font-size: 0.75rem;\n",
        "            font-weight: 700;\n",
        "            text-transform: uppercase;\n",
        "            letter-spacing: 0.05em;\n",
        "            display: inline-block;\n",
        "            margin-bottom: 24px;\n",
        "            box-shadow: 0 4px 12px rgba(124, 58, 237, 0.3);\n",
        "            text-align: center;\n",
        "            width: fit-content;\n",
        "        }\n",
        "        \n",
        "        .account-display {\n",
        "            background: rgba(255, 255, 255, 0.05);\n",
        "            padding: 12px;\n",
        "            border-radius: 12px;\n",
        "            margin-bottom: 20px;\n",
        "            font-size: 0.9rem;\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            gap: 10px;\n",
        "            border: 1px solid rgba(255,255,255,0.1);\n",
        "        }\n",
        "\n",
        "        /* Main Panel Styling */\n",
        "        .main-panel {\n",
        "            padding: 0;\n",
        "            height: 100vh;\n",
        "            overflow-y: auto;\n",
        "            background: transparent;\n",
        "        }\n",
        "        \n",
        "        .header-section {\n",
        "            padding: 20px 40px;\n",
        "            border-bottom: 1px solid rgba(255,255,255,0.05);\n",
        "            background: rgba(15, 5, 24, 0.5);\n",
        "            backdrop-filter: blur(10px);\n",
        "            display: flex;\n",
        "            justify-content: space-between;\n",
        "            align-items: center;\n",
        "        }\n",
        "\n",
        "        .header-pill {\n",
        "            background: rgba(124, 58, 237, 0.15);\n",
        "            padding: 6px 16px;\n",
        "            border-radius: 999px;\n",
        "            font-size: 0.8rem;\n",
        "            color: #d8b4fe;\n",
        "            border: 1px solid rgba(124, 58, 237, 0.3);\n",
        "            font-weight: 500;\n",
        "        }\n",
        "\n",
        "        /* Tabs Styling */\n",
        "        .tabs {\n",
        "            margin-top: 0px;\n",
        "            border-bottom: 1px solid rgba(255,255,255,0.05);\n",
        "        }\n",
        "        .tab-nav {\n",
        "            border: none !important;\n",
        "            background: transparent !important;\n",
        "        }\n",
        "        .tab-nav button {\n",
        "            color: #9ca3af !important;\n",
        "            font-weight: 500;\n",
        "        }\n",
        "        .tab-nav button.selected {\n",
        "            border-bottom: 2px solid #d8b4fe !important;\n",
        "            color: #d8b4fe !important;\n",
        "            background: transparent !important;\n",
        "            font-weight: 700;\n",
        "        }\n",
        "\n",
        "        /* Chatbot Styling */\n",
        "        .bubble-wrap {\n",
        "            background-color: #1e1035 !important;\n",
        "            border: 1px solid rgba(255,255,255,0.08) !important;\n",
        "            border-radius: 16px !important;\n",
        "            box-shadow: 0 4px 20px rgba(0,0,0,0.2);\n",
        "        }\n",
        "        \n",
        "        /* Input Area */\n",
        "        .input-box textarea {\n",
        "            background-color: #1e1035 !important;\n",
        "            border: 1px solid rgba(124, 58, 237, 0.3) !important;\n",
        "            color: white !important;\n",
        "            border-radius: 12px !important;\n",
        "            padding: 12px !important;\n",
        "        }\n",
        "        .input-box textarea:focus {\n",
        "            border-color: #a78bfa !important;\n",
        "            box-shadow: 0 0 0 2px rgba(167, 139, 250, 0.2) !important;\n",
        "        }\n",
        "\n",
        "        /* Buttons */\n",
        "        button.primary {\n",
        "            background: linear-gradient(90deg, #7c3aed, #6d28d9) !important;\n",
        "            color: white !important;\n",
        "            border: none !important;\n",
        "            border-radius: 8px !important;\n",
        "            font-weight: 600 !important;\n",
        "            transition: all 0.2s;\n",
        "        }\n",
        "        button.primary:hover {\n",
        "            box-shadow: 0 0 15px rgba(124, 58, 237, 0.5) !important;\n",
        "            transform: translateY(-1px);\n",
        "        }\n",
        "        \n",
        "        button.secondary {\n",
        "            background-color: rgba(255,255,255,0.05) !important;\n",
        "            color: #e9d5ff !important;\n",
        "            border: 1px solid rgba(255,255,255,0.1) !important;\n",
        "            border-radius: 8px !important;\n",
        "        }\n",
        "\n",
        "        /* Landing Page Hero */\n",
        "        .hero-container {\n",
        "            text-align: center;\n",
        "            padding: 60px 20px;\n",
        "            max-width: 800px;\n",
        "            margin: 0 auto;\n",
        "        }\n",
        "        .hero-icon {\n",
        "            font-size: 4rem;\n",
        "            margin-bottom: 20px;\n",
        "            background: linear-gradient(135deg, #a78bfa, #f472b6);\n",
        "            -webkit-background-clip: text;\n",
        "            -webkit-text-fill-color: transparent;\n",
        "        }\n",
        "        .hero-title {\n",
        "            font-size: 2.5rem;\n",
        "            font-weight: 800;\n",
        "            margin-bottom: 16px;\n",
        "            color: white;\n",
        "            line-height: 1.2;\n",
        "        }\n",
        "        .hero-subtitle {\n",
        "            font-size: 1.1rem;\n",
        "            color: #9ca3af;\n",
        "            line-height: 1.6;\n",
        "            margin-bottom: 40px;\n",
        "        }\n",
        "        .feature-grid {\n",
        "            display: grid;\n",
        "            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n",
        "            gap: 20px;\n",
        "            margin-top: 40px;\n",
        "        }\n",
        "        .feature-card {\n",
        "            background: rgba(255,255,255,0.03);\n",
        "            border: 1px solid rgba(255,255,255,0.05);\n",
        "            padding: 20px;\n",
        "            border-radius: 16px;\n",
        "            text-align: center;\n",
        "            transition: transform 0.2s;\n",
        "        }\n",
        "        .feature-card:hover {\n",
        "            transform: translateY(-5px);\n",
        "            background: rgba(255,255,255,0.05);\n",
        "            border-color: rgba(124, 58, 237, 0.3);\n",
        "        }\n",
        "\n",
        "        /* Hide footer */\n",
        "        footer { display: none !important; }\n",
        "    </style>\n",
        "    \"\"\")\n",
        "\n",
        "    chat_histories = gr.State({\"Chat 1\": []})\n",
        "    current_chat = gr.State(\"Chat 1\")\n",
        "    account_name_state = gr.State(\"Guest Account\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # ========= Sidebar (Left) =========\n",
        "        with gr.Column(scale=1, min_width=280):\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                <div class=\"app-logo\">FitMate</div>\n",
        "                <div class=\"app-subtitle\">AI Fitness Coach</div>\n",
        "                <div class=\"pro-badge\">\ud83c\udfc6 Pro Plan Unlimited</div>\n",
        "                \"\"\"\n",
        "            )\n",
        "            \n",
        "            account_md = gr.Markdown(\n",
        "                \"<div class='account-display'>\ud83d\udc64 Guest Account</div>\"\n",
        "            )\n",
        "            \n",
        "            new_chat_btn = gr.Button(\"+ New Chat\", variant=\"primary\")\n",
        "            \n",
        "            gr.Markdown(\"### Your Chats\")\n",
        "            \n",
        "            # Chat list (Radio)\n",
        "            chat_selector = gr.Radio(\n",
        "                choices=[\"Chat 1\"],\n",
        "                value=\"Chat 1\",\n",
        "                label=\"\",\n",
        "                interactive=True\n",
        "            )\n",
        "            \n",
        "            gr.Markdown(\"---\")\n",
        "            delete_chat_btn = gr.Button(\"\ud83d\uddd1\ufe0f Delete Chat\", variant=\"secondary\")\n",
        "\n",
        "        # ========= Main Panel (Right) =========\n",
        "        with gr.Column(scale=4):\n",
        "            \n",
        "            # Header\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=3):\n",
        "                    gr.Markdown(\n",
        "                        \"\"\"\n",
        "                        # Dashboard\n",
        "                        \"\"\"\n",
        "                    )\n",
        "                with gr.Column(scale=1):\n",
        "                     gr.HTML(\n",
        "                        \"\"\"\n",
        "                        <div style=\"display:flex; gap:8px; justify-content:flex-end; margin-top: 10px;\">\n",
        "                            <span class=\"header-pill\">\ud83d\udd25 Pro Active</span>\n",
        "                            <span class=\"header-pill\">\u26a1 Turbo Mode</span>\n",
        "                        </div>\n",
        "                        \"\"\"\n",
        "                    )\n",
        "\n",
        "            with gr.Tabs():\n",
        "                \n",
        "                # 1. Overview Tab (Landing Page Style)\n",
        "                with gr.Tab(\"\ud83c\udfe0 Home\"):\n",
        "                    gr.HTML(\n",
        "                        \"\"\"\n",
        "                        <div class=\"hero-container\">\n",
        "                            <div class=\"hero-icon\">\ud83d\udcaa</div>\n",
        "                            <h1 class=\"hero-title\">Transform Your Fitness Journey</h1>\n",
        "                            <p class=\"hero-subtitle\">\n",
        "                                Your personal AI coach for custom workouts, nutrition plans, and recovery advice. \n",
        "                                Powered by advanced AI to guide you step-by-step.\n",
        "                            </p>\n",
        "                            \n",
        "                            <div class=\"feature-grid\">\n",
        "                                <div class=\"feature-card\">\n",
        "                                    <div style=\"font-size:2rem; margin-bottom:10px;\">\ud83c\udfcb\ufe0f</div>\n",
        "                                    <div style=\"font-weight:bold; color:white;\">Smart Workouts</div>\n",
        "                                    <div style=\"font-size:0.8rem; color:#9ca3af;\">Personalized routines</div>\n",
        "                                </div>\n",
        "                                <div class=\"feature-card\">\n",
        "                                    <div style=\"font-size:2rem; margin-bottom:10px;\">\ud83e\udd57</div>\n",
        "                                    <div style=\"font-weight:bold; color:white;\">Nutrition Plans</div>\n",
        "                                    <div style=\"font-size:0.8rem; color:#9ca3af;\">Macros & Meal Prep</div>\n",
        "                                </div>\n",
        "                                <div class=\"feature-card\">\n",
        "                                    <div style=\"font-size:2rem; margin-bottom:10px;\">\ud83e\udde0</div>\n",
        "                                    <div style=\"font-weight:bold; color:white;\">Expert Knowledge</div>\n",
        "                                    <div style=\"font-size:0.8rem; color:#9ca3af;\">RAG & Web Search</div>\n",
        "                                </div>\n",
        "                                <div class=\"feature-card\">\n",
        "                                    <div style=\"font-size:2rem; margin-bottom:10px;\">\u26a1</div>\n",
        "                                    <div style=\"font-weight:bold; color:white;\">Instant Answers</div>\n",
        "                                    <div style=\"font-size:0.8rem; color:#9ca3af;\">24/7 Availability</div>\n",
        "                                </div>\n",
        "                            </div>\n",
        "                            \n",
        "                            <div style=\"margin-top: 40px; padding: 20px; background: rgba(124, 58, 237, 0.1); border-radius: 12px; border: 1px solid rgba(124, 58, 237, 0.3);\">\n",
        "                                <div style=\"font-weight:bold; color:#d8b4fe; margin-bottom:8px;\">\ud83d\ude80 Ready to start?</div>\n",
        "                                <div style=\"color:#e9d5ff; font-size:0.9rem;\">Switch to the <b>Chat Tab</b> to begin your session.</div>\n",
        "                            </div>\n",
        "                        </div>\n",
        "                        \"\"\"\n",
        "                    )\n",
        "\n",
        "                # 2. Chat Tab\n",
        "                with gr.Tab(\"\ud83d\udcac Chat\"):\n",
        "                    chatbot = gr.Chatbot(\n",
        "                        label=\"FitMate Pro\",\n",
        "                        height=600\n",
        "                    )\n",
        "                    \n",
        "                    with gr.Row():\n",
        "                        msg = gr.Textbox(\n",
        "                            placeholder=\"Ask FitMate anything...\",\n",
        "                            show_label=False,\n",
        "                            lines=3,\n",
        "                            scale=8\n",
        "                        )\n",
        "                        with gr.Column(scale=1):\n",
        "                            send_btn = gr.Button(\"Send \u27a4\", variant=\"primary\")\n",
        "                            clear_btn = gr.Button(\"Clear\", variant=\"secondary\")\n",
        "\n",
        "                # 3. Documents Tab\n",
        "                with gr.Tab(\"\ud83d\udcc4 Knowledge Base\"):\n",
        "                    with gr.Row():\n",
        "                        with gr.Column():\n",
        "                            gr.Markdown(\"### \ud83d\udcc2 Upload Context\")\n",
        "                            gr.Markdown(\"Enhance your AI coach with personal documents (PDFs).\")\n",
        "                            \n",
        "                            pdf_upload = gr.File(\n",
        "                                label=\"Upload PDF\",\n",
        "                                file_types=[\".pdf\"],\n",
        "                                file_count=\"single\"\n",
        "                            )\n",
        "                            upload_btn = gr.Button(\"Process Document\", variant=\"primary\")\n",
        "                            upload_status = gr.Textbox(label=\"Processing Status\", interactive=False)\n",
        "                            \n",
        "                            gr.Markdown(\"---\")\n",
        "                            clear_docs_btn = gr.Button(\"\ud83d\uddd1\ufe0f Clear Memory\", variant=\"stop\")\n",
        "                            clear_docs_status = gr.Textbox(label=\"Memory Status\", interactive=False)\n",
        "\n",
        "                # 4. Settings Tab\n",
        "                with gr.Tab(\"\u2699\ufe0f Settings\"):\n",
        "                    with gr.Row():\n",
        "                        with gr.Column():\n",
        "                            gr.Markdown(\"### \ud83d\udc64 User Profile\")\n",
        "                            display_name_box = gr.Textbox(label=\"Display Name\", value=\"Guest Account\")\n",
        "                            \n",
        "                            gr.Markdown(\"### \ud83d\udcac Session Management\")\n",
        "                            chat_name_box = gr.Textbox(label=\"Rename Current Chat\", value=\"Chat 1\")\n",
        "                            rename_chat_btn = gr.Button(\"Update Name\")\n",
        "                            \n",
        "                        with gr.Column():\n",
        "                            gr.Markdown(\"### \u26a1 Pro Configuration\")\n",
        "                            \n",
        "                            # Visual \"Plan\" indicator\n",
        "                            gr.HTML(\"\"\"\n",
        "                            <div style=\"background: rgba(124, 58, 237, 0.1); padding: 15px; border-radius: 8px; border: 1px solid rgba(124, 58, 237, 0.3); margin-bottom: 20px;\">\n",
        "                                <div style=\"font-weight: bold; color: #d8b4fe;\">Current Plan: Pro Unlimited</div>\n",
        "                                <div style=\"font-size: 0.8rem; color: #a78bfa;\">You have access to maximum context window and web search capabilities.</div>\n",
        "                            </div>\n",
        "                            \"\"\")\n",
        "                            \n",
        "                            lora_mode = gr.Dropdown(\n",
        "                                choices=[\n",
        "                                    \"Standard coach (default)\",\n",
        "                                    \"Fat-loss focused\",\n",
        "                                    \"Muscle-building focused\",\n",
        "                                    \"Rehab & mobility focused\",\n",
        "                                ],\n",
        "                                value=\"Standard coach (default)\",\n",
        "                                label=\"Coaching Focus\"\n",
        "                            )\n",
        "                            \n",
        "                            enable_web = gr.Checkbox(\n",
        "                                value=True,\n",
        "                                label=\"Enable Web Search (Pro Feature)\"\n",
        "                            )\n",
        "                            \n",
        "                            max_tokens_slider = gr.Slider(\n",
        "                                minimum=256,\n",
        "                                maximum=2048,\n",
        "                                value=2048, # Set to max for \"Pro\" feel\n",
        "                                step=64,\n",
        "                                label=\"Response Length (Pro Limit: 2048)\"\n",
        "                            )\n",
        "\n",
        "    # ---------- Wiring: New Chat ----------\n",
        "    new_chat_btn.click(\n",
        "        create_new_chat,\n",
        "        inputs=[chat_histories],\n",
        "        outputs=[chat_histories, current_chat, chat_selector, chatbot],\n",
        "    ).then(\n",
        "        set_chat_name_box,\n",
        "        inputs=[current_chat],\n",
        "        outputs=[chat_name_box],\n",
        "    )\n",
        "\n",
        "    # ---------- Wiring: Switch Chat ----------\n",
        "    chat_selector.change(\n",
        "        switch_chat,\n",
        "        inputs=[chat_selector, chat_histories],\n",
        "        outputs=[chatbot],\n",
        "    ).then(\n",
        "        lambda selected: selected,\n",
        "        inputs=[chat_selector],\n",
        "        outputs=[current_chat],\n",
        "    ).then(\n",
        "        set_chat_name_box,\n",
        "        inputs=[chat_selector],\n",
        "        outputs=[chat_name_box],\n",
        "    )\n",
        "\n",
        "    # ---------- Wiring: Delete Chat ----------\n",
        "    delete_chat_btn.click(\n",
        "        delete_chat,\n",
        "        inputs=[chat_histories, current_chat],\n",
        "        outputs=[chat_histories, current_chat, chat_selector, chatbot],\n",
        "    ).then(\n",
        "        set_chat_name_box,\n",
        "        inputs=[current_chat],\n",
        "        outputs=[chat_name_box],\n",
        "    )\n",
        "\n",
        "    # ---------- Wiring: Chat ----------\n",
        "    send_btn.click(\n",
        "        add_user_message,\n",
        "        inputs=[msg, chat_histories, current_chat],\n",
        "        outputs=[chat_histories, chatbot],\n",
        "    ).then(\n",
        "        generate_bot_reply,\n",
        "        inputs=[enable_web, max_tokens_slider, lora_mode, chat_histories, current_chat],\n",
        "        outputs=[chat_histories, chatbot],\n",
        "    ).then(\n",
        "        lambda: \"\",\n",
        "        inputs=None,\n",
        "        outputs=msg,\n",
        "    )\n",
        "\n",
        "    msg.submit(\n",
        "        add_user_message,\n",
        "        inputs=[msg, chat_histories, current_chat],\n",
        "        outputs=[chat_histories, chatbot],\n",
        "    ).then(\n",
        "        generate_bot_reply,\n",
        "        inputs=[enable_web, max_tokens_slider, lora_mode, chat_histories, current_chat],\n",
        "        outputs=[chat_histories, chatbot],\n",
        "    ).then(\n",
        "        lambda: \"\",\n",
        "        inputs=None,\n",
        "        outputs=msg,\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        clear_current_chat,\n",
        "        inputs=[chat_histories, current_chat],\n",
        "        outputs=[chat_histories, chatbot],\n",
        "    )\n",
        "\n",
        "    # ---------- Wiring: Documents ----------\n",
        "    upload_btn.click(upload_pdf, [pdf_upload], [upload_status])\n",
        "    clear_docs_btn.click(clear_documents, None, [clear_docs_status])\n",
        "\n",
        "    # ---------- Wiring: Account name ----------\n",
        "    display_name_box.change(\n",
        "        update_account_name,\n",
        "        inputs=[display_name_box],\n",
        "        outputs=[account_name_state, account_md],\n",
        "    )\n",
        "\n",
        "    # ---------- Wiring: Rename chat ----------\n",
        "    rename_chat_btn.click(\n",
        "        rename_chat,\n",
        "        inputs=[chat_name_box, chat_histories, current_chat],\n",
        "        outputs=[chat_histories, current_chat, chat_selector, chat_name_box],\n",
        "    )\n",
        "\n",
        "print(\"\\\\n\" + \"=\"*50)\n",
        "print(\"\ud83d\ude80 Launching FitMate Pro Interface...\")\n",
        "print(\"=\"*50 + \"\\\\n\")\n",
        "\n",
        "demo.launch(\n",
        "    share=True,\n",
        "    debug=False,\n",
        "    show_error=True,\n",
        "    quiet=False,\n",
        ")\n",
        "# ===================== END =====================\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u23f3 Loading FitMate model on GPU if available...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2798d54a426f4bceb16333710c4b1ef5",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "tokenizer_config.json: 0.00B [00:00, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70e44ea79bb643068f9f7434d720f6ed",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "tokenizer.json:   0%|          | 0.00/27.9M [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9100e2ff2e094e6eba341dedc01a8d8c",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/446 [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdb058789f8b49bb97c8e0613c78886d",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "chat_template.jinja: 0.00B [00:00, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying to load model in 4-bit quantization...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9cc3771ac37462c8b3aa63ac72a1e19",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "config.json: 0.00B [00:00, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u26a0\ufe0f 4-bit load failed, falling back to standard fp16/fp32. Reason: The model is quantized with Mxfp4Config but you are passing a BitsAndBytesConfig config. Please make sure to pass the same quantization config class to `from_pretrained` with different loading attributes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MXFP4 quantization requires triton >= 3.4.0 and kernels installed, we will default to dequantizing the model to bf16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ae5a7a0b30b44d39fc40284a1f662b6",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9a5af4b6d2d4372af71258fc2becbef",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e6dcb32c99246aa9be0c0df6a73830f",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "model-00000-of-00002.safetensors:   0%|          | 0.00/4.79G [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c61b885954dd49ebbf29b28d5590c563",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "model-00002-of-00002.safetensors:   0%|          | 0.00/4.17G [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03ce5144ceb94db2be8693de8b8f6fe8",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "model-00001-of-00002.safetensors:   0%|          | 0.00/4.80G [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "577b8521b3b4445a9a9ab02805d562c1",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "589bd11ea5034243a5ae24ada1ee0199",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "generation_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 FitMate loaded on: cuda\n",
            "GPU: NVIDIA A100-SXM4-80GB\n",
            "\n",
            "Initializing vector store...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e44ff46464645ad9aae0b596d62bdce",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "828ea54671e844d5ae21d7b5feb33761",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b44733b041764eeead121b0880c69ede",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "README.md: 0.00B [00:00, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ea8d27c3c2e4d32834aefa5f6b0b668",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb3f2f5a45dc401fa5078b3fa5ccee83",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6e5f80fbfd949e8bd7a84717a8e7082",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b53e851333a2406c8820e9e511302b90",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55c5ab8b73fb4def906cc25c257b7230",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a76f84e9fdb449bbcd73bbb44952c4b",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "tokenizer.json: 0.00B [00:00, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f692f88631684d3788843d2c4ea60306",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c282930f904401b8ec8a39bcf4f7185",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Vector store ready!\n",
            "\n",
            "\n",
            "==================================================\n",
            "\ud83d\ude80 Launching FitMate Agent Interface (Fast)\u2026\n",
            "==================================================\n",
            "\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://f137a2b60cb6308573.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<div><iframe src=\"https://f137a2b60cb6308573.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}